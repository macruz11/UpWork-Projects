{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a4f7b99",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-02T16:59:53.342594Z",
     "iopub.status.busy": "2024-10-02T16:59:53.342187Z",
     "iopub.status.idle": "2024-10-02T16:59:54.281740Z",
     "shell.execute_reply": "2024-10-02T16:59:54.280275Z"
    },
    "papermill": {
     "duration": 0.946796,
     "end_time": "2024-10-02T16:59:54.284663",
     "exception": false,
     "start_time": "2024-10-02T16:59:53.337867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/pdfsss3/pdf2.pdf\n",
      "/kaggle/input/pdfsss3/pdf5.pdf\n",
      "/kaggle/input/pdfsss3/pdf4.pdf\n",
      "/kaggle/input/pdfsss3/pdf8.pdf\n",
      "/kaggle/input/pdfsss3/pdf1.pdf\n",
      "/kaggle/input/pdfsss3/pdf11.pdf\n",
      "/kaggle/input/pdfsss3/pdf7.pdf\n",
      "/kaggle/input/pdfsss3/pdf10.pdf\n",
      "/kaggle/input/pdfsss3/pdf9.pdf\n",
      "/kaggle/input/pdfsss3/pdf3.pdf\n",
      "/kaggle/input/pdfsss3/pdf6.pdf\n",
      "/kaggle/input/pdfsss/pdf2.pdf\n",
      "/kaggle/input/pdfsss/pdf1.pdf\n",
      "/kaggle/input/pdfsss/pdf3.pdf\n",
      "/kaggle/input/pdfsss2/pdf2.pdf\n",
      "/kaggle/input/pdfsss2/pdf4.pdf\n",
      "/kaggle/input/pdfsss2/pdf1.pdf\n",
      "/kaggle/input/pdfsss2/pdf3.pdf\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "964256dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T16:59:54.291136Z",
     "iopub.status.busy": "2024-10-02T16:59:54.290606Z",
     "iopub.status.idle": "2024-10-02T17:00:08.614664Z",
     "shell.execute_reply": "2024-10-02T17:00:08.613274Z"
    },
    "papermill": {
     "duration": 14.329919,
     "end_time": "2024-10-02T17:00:08.617114",
     "exception": false,
     "start_time": "2024-10-02T16:59:54.287195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\r\n",
      "  Downloading pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\r\n",
      "Requirement already satisfied: openpyxl in /opt/conda/lib/python3.10/site-packages (3.1.5)\r\n",
      "Collecting pdfminer.six==20231228 (from pdfplumber)\r\n",
      "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\r\n",
      "Requirement already satisfied: Pillow>=9.1 in /opt/conda/lib/python3.10/site-packages (from pdfplumber) (10.3.0)\r\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\r\n",
      "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\r\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (42.0.8)\r\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\r\n",
      "Requirement already satisfied: et-xmlfile in /opt/conda/lib/python3.10/site-packages (from openpyxl) (1.1.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\r\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.16.0)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\r\n",
      "Downloading pdfplumber-0.11.4-py3-none-any.whl (59 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\r\n",
      "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.4 pypdfium2-4.30.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pdfplumber pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ff694fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T17:00:08.626868Z",
     "iopub.status.busy": "2024-10-02T17:00:08.626022Z",
     "iopub.status.idle": "2024-10-02T17:00:17.351058Z",
     "shell.execute_reply": "2024-10-02T17:00:17.349786Z"
    },
    "papermill": {
     "duration": 8.732931,
     "end_time": "2024-10-02T17:00:17.353429",
     "exception": false,
     "start_time": "2024-10-02T17:00:08.620498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while converting /kaggle/input/your-dataset/pdf1.pdf to CSV: [Errno 2] No such file or directory: '/kaggle/input/your-dataset/pdf1.pdf'\n",
      "Error while converting /kaggle/input/your-dataset/pdf2.pdf to CSV: [Errno 2] No such file or directory: '/kaggle/input/your-dataset/pdf2.pdf'\n",
      "Error while converting /kaggle/input/your-dataset/pdf3.pdf to CSV: [Errno 2] No such file or directory: '/kaggle/input/your-dataset/pdf3.pdf'\n",
      "Error while converting /kaggle/input/your-dataset/pdf4.pdf to CSV: [Errno 2] No such file or directory: '/kaggle/input/your-dataset/pdf4.pdf'\n",
      "Error while converting /kaggle/input/your-dataset/pdf5.pdf to CSV: [Errno 2] No such file or directory: '/kaggle/input/your-dataset/pdf5.pdf'\n",
      "CSV /kaggle/working/pdf6.csv created successfully from /kaggle/input/pdfsss3/pdf6.pdf.\n",
      "CSV /kaggle/working/pdf7.csv created successfully from /kaggle/input/pdfsss3/pdf7.pdf.\n",
      "CSV /kaggle/working/pdf8.csv created successfully from /kaggle/input/pdfsss3/pdf8.pdf.\n",
      "CSV /kaggle/working/pdf9.csv created successfully from /kaggle/input/pdfsss3/pdf9.pdf.\n",
      "CSV /kaggle/working/pdf10.csv created successfully from /kaggle/input/pdfsss3/pdf10.pdf.\n",
      "CSV /kaggle/working/pdf11.csv created successfully from /kaggle/input/pdfsss3/pdf11.pdf.\n",
      "Error while importing /kaggle/working/pdf1.csv to Excel: [Errno 2] No such file or directory: '/kaggle/working/pdf1.csv'\n",
      "Error while importing /kaggle/working/pdf2.csv to Excel: [Errno 2] No such file or directory: '/kaggle/working/pdf2.csv'\n",
      "Error while importing /kaggle/working/pdf3.csv to Excel: [Errno 2] No such file or directory: '/kaggle/working/pdf3.csv'\n",
      "Error while importing /kaggle/working/pdf4.csv to Excel: [Errno 2] No such file or directory: '/kaggle/working/pdf4.csv'\n",
      "Error while importing /kaggle/working/pdf5.csv to Excel: [Errno 2] No such file or directory: '/kaggle/working/pdf5.csv'\n",
      "Data from /kaggle/working/pdf6.csv has been imported into Excel sheet 'pdf6'.\n",
      "Data from /kaggle/working/pdf7.csv has been imported into Excel sheet 'pdf7'.\n",
      "Data from /kaggle/working/pdf8.csv has been imported into Excel sheet 'pdf8'.\n",
      "Data from /kaggle/working/pdf9.csv has been imported into Excel sheet 'pdf9'.\n",
      "Data from /kaggle/working/pdf10.csv has been imported into Excel sheet 'pdf10'.\n",
      "Data from /kaggle/working/pdf11.csv has been imported into Excel sheet 'pdf11'.\n",
      "All CSV files have been imported into /kaggle/working/imported_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to extract all text from a PDF and save it to CSV\n",
    "def convert_pdf_to_word_csv(pdf_path, output_dir):\n",
    "    \"\"\"\n",
    "    Extracts all text from a PDF file, splits it by spaces into individual words,\n",
    "    and saves it as a CSV file where each word is in a separate cell.\n",
    "    \n",
    "    Parameters:\n",
    "    - pdf_path: Path to the PDF file\n",
    "    - output_dir: Directory to save the output CSV file\n",
    "    \n",
    "    Returns:\n",
    "    - output_csv: Path to the generated CSV file\n",
    "    \"\"\"\n",
    "    output_csv = os.path.join(output_dir, os.path.basename(pdf_path).replace(\".pdf\", \".csv\"))\n",
    "\n",
    "    # Initialize an empty list to store rows (each row is a list of words)\n",
    "    word_rows = []\n",
    "\n",
    "    try:\n",
    "        # Open the PDF file using pdfplumber\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            # Iterate through all the pages in the PDF\n",
    "            for page in pdf.pages:\n",
    "                text = page.extract_text()\n",
    "                if text:\n",
    "                    # Split each line into words based on space and add to rows\n",
    "                    lines = text.split('\\n')\n",
    "                    for line in lines:\n",
    "                        words = line.split()  # Splitting the line by spaces into words\n",
    "                        word_rows.append(words)\n",
    "\n",
    "        # Write the extracted words into a CSV file\n",
    "        pd.DataFrame(word_rows).to_csv(output_csv, index=False, header=False, encoding='utf-8')\n",
    "        print(f\"CSV {output_csv} created successfully from {pdf_path}.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error while converting {pdf_path} to CSV: {e}\")\n",
    "\n",
    "    return output_csv\n",
    "\n",
    "# Function to import CSV files into Excel\n",
    "def import_csvs_to_excel(csv_files, excel_path):\n",
    "    \"\"\"\n",
    "    Imports the word-separated CSV files into an Excel workbook, each CSV in a separate sheet.\n",
    "    \n",
    "    Parameters:\n",
    "    - csv_files: List of paths to the CSV files\n",
    "    - excel_path: Path to the Excel file\n",
    "    \"\"\"\n",
    "    # Create an Excel writer object\n",
    "    with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "        # Loop through each CSV file\n",
    "        for csv_file in csv_files:\n",
    "            try:\n",
    "                # Read the CSV file as a pandas DataFrame (words are already separated)\n",
    "                df = pd.read_csv(csv_file, header=None)\n",
    "\n",
    "                # Check if the DataFrame is empty\n",
    "                if df.empty:\n",
    "                    print(f\"Warning: {csv_file} is empty or cannot be parsed.\")\n",
    "                else:\n",
    "                    # Generate a sheet name based on the file name (without extension)\n",
    "                    sheet_name = os.path.basename(csv_file).replace('.csv', '')\n",
    "\n",
    "                    # Write the DataFrame to a new sheet in the Excel workbook\n",
    "                    df.to_excel(writer, sheet_name=sheet_name, index=False, header=False)\n",
    "                    print(f\"Data from {csv_file} has been imported into Excel sheet '{sheet_name}'.\")\n",
    "            except pd.errors.EmptyDataError:\n",
    "                print(f\"Error: {csv_file} is empty or has no data to parse.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error while importing {csv_file} to Excel: {e}\")\n",
    "\n",
    "    print(f\"All CSV files have been imported into {excel_path}\")\n",
    "\n",
    "# Main function to automate PDF to Excel conversion\n",
    "def automate_pdf_to_excel(pdf_files, output_directory, excel_file):\n",
    "    \"\"\"\n",
    "    Automates the process of converting PDFs to CSV (with words split into separate cells) \n",
    "    and importing them into Excel.\n",
    "    \n",
    "    Parameters:\n",
    "    - pdf_files: List of paths to the PDF files\n",
    "    - output_directory: Directory to save the converted CSVs\n",
    "    - excel_file: Path to the final Excel file\n",
    "    \"\"\"\n",
    "    # List to store paths of converted CSV files\n",
    "    csv_files = []\n",
    "\n",
    "    # Convert each PDF to CSV (splitting text into words) and store the CSV paths\n",
    "    for pdf_file in pdf_files:\n",
    "        csv_file = convert_pdf_to_word_csv(pdf_file, output_directory)\n",
    "        csv_files.append(csv_file)\n",
    "\n",
    "    # Import all CSV files into the Excel file\n",
    "    import_csvs_to_excel(csv_files, excel_file)\n",
    "\n",
    "# Paths to the PDF files (replace with your actual file paths)\n",
    "pdf_files = [\n",
    "    \"/kaggle/input/your-dataset/pdf1.pdf\",\n",
    "    \"/kaggle/input/your-dataset/pdf2.pdf\",\n",
    "    \"/kaggle/input/your-dataset/pdf3.pdf\",\n",
    "    \"/kaggle/input/your-dataset/pdf4.pdf\",\n",
    "    \"/kaggle/input/your-dataset/pdf5.pdf\",\n",
    "    \"/kaggle/input/pdfsss3/pdf6.pdf\",\n",
    "    \"/kaggle/input/pdfsss3/pdf7.pdf\",\n",
    "    \"/kaggle/input/pdfsss3/pdf8.pdf\",\n",
    "    \"/kaggle/input/pdfsss3/pdf9.pdf\",\n",
    "    \"/kaggle/input/pdfsss3/pdf10.pdf\",\n",
    "    \"/kaggle/input/pdfsss3/pdf11.pdf\"\n",
    "]\n",
    "\n",
    "# Directory where the converted CSVs will be saved\n",
    "output_directory = \"/kaggle/working/\"\n",
    "\n",
    "# Path to the final Excel file where the data will be stored\n",
    "excel_file = \"/kaggle/working/imported_data.xlsx\"\n",
    "\n",
    "# Run the automation process to extract text from PDFs and import to Excel\n",
    "automate_pdf_to_excel(pdf_files, output_directory, excel_file)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5790577,
     "sourceId": 9512642,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5795271,
     "sourceId": 9518762,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5801120,
     "sourceId": 9526538,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27.308097,
   "end_time": "2024-10-02T17:00:17.879184",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-02T16:59:50.571087",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
