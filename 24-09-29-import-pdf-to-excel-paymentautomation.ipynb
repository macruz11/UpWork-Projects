{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dd05256",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-30T18:31:41.896101Z",
     "iopub.status.busy": "2024-09-30T18:31:41.895530Z",
     "iopub.status.idle": "2024-09-30T18:31:42.780341Z",
     "shell.execute_reply": "2024-09-30T18:31:42.779236Z"
    },
    "papermill": {
     "duration": 0.892681,
     "end_time": "2024-09-30T18:31:42.782956",
     "exception": false,
     "start_time": "2024-09-30T18:31:41.890275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/pdfsss/pdf2.pdf\n",
      "/kaggle/input/pdfsss/pdf1.pdf\n",
      "/kaggle/input/pdfsss/pdf3.pdf\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "009b2a07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T18:31:42.790735Z",
     "iopub.status.busy": "2024-09-30T18:31:42.789578Z",
     "iopub.status.idle": "2024-09-30T18:31:59.399567Z",
     "shell.execute_reply": "2024-09-30T18:31:59.397803Z"
    },
    "papermill": {
     "duration": 16.617124,
     "end_time": "2024-09-30T18:31:59.402915",
     "exception": false,
     "start_time": "2024-09-30T18:31:42.785791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\r\n",
      "  Downloading pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\r\n",
      "Requirement already satisfied: openpyxl in /opt/conda/lib/python3.10/site-packages (3.1.5)\r\n",
      "Collecting pdfminer.six==20231228 (from pdfplumber)\r\n",
      "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\r\n",
      "Requirement already satisfied: Pillow>=9.1 in /opt/conda/lib/python3.10/site-packages (from pdfplumber) (10.3.0)\r\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\r\n",
      "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\r\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (42.0.8)\r\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\r\n",
      "Requirement already satisfied: et-xmlfile in /opt/conda/lib/python3.10/site-packages (from openpyxl) (1.1.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\r\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.16.0)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\r\n",
      "Downloading pdfplumber-0.11.4-py3-none-any.whl (59 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\r\n",
      "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.4 pypdfium2-4.30.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pdfplumber pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd6eb4c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T18:31:59.414711Z",
     "iopub.status.busy": "2024-09-30T18:31:59.414238Z",
     "iopub.status.idle": "2024-09-30T18:32:00.763605Z",
     "shell.execute_reply": "2024-09-30T18:32:00.762164Z"
    },
    "papermill": {
     "duration": 1.358431,
     "end_time": "2024-09-30T18:32:00.766298",
     "exception": false,
     "start_time": "2024-09-30T18:31:59.407867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV /kaggle/working/pdf1.csv created successfully from /kaggle/input/pdfsss/pdf1.pdf.\n",
      "CSV /kaggle/working/pdf2.csv created successfully from /kaggle/input/pdfsss/pdf2.pdf.\n",
      "CSV /kaggle/working/pdf3.csv created successfully from /kaggle/input/pdfsss/pdf3.pdf.\n",
      "Data from /kaggle/working/pdf1.csv has been imported into Excel sheet 'pdf1'.\n",
      "Data from /kaggle/working/pdf2.csv has been imported into Excel sheet 'pdf2'.\n",
      "Data from /kaggle/working/pdf3.csv has been imported into Excel sheet 'pdf3'.\n",
      "All CSV files have been imported into /kaggle/working/imported_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to extract all text from a PDF and save it to CSV\n",
    "def convert_pdf_to_text_csv(pdf_path, output_dir):\n",
    "    \"\"\"\n",
    "    Extracts all text from a PDF file and saves it as a CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    - pdf_path: Path to the PDF file\n",
    "    - output_dir: Directory to save the output CSV file\n",
    "    \n",
    "    Returns:\n",
    "    - output_csv: Path to the generated CSV file\n",
    "    \"\"\"\n",
    "    output_csv = os.path.join(output_dir, os.path.basename(pdf_path).replace(\".pdf\", \".csv\"))\n",
    "\n",
    "    # Initialize an empty list to store the lines of text\n",
    "    extracted_text = []\n",
    "\n",
    "    try:\n",
    "        # Open the PDF file using pdfplumber\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            # Iterate through all the pages in the PDF\n",
    "            for page in pdf.pages:\n",
    "                text = page.extract_text()\n",
    "                if text:\n",
    "                    # Split the extracted text into lines and append to the list\n",
    "                    lines = text.split('\\n')\n",
    "                    extracted_text.extend(lines)\n",
    "        \n",
    "        # Write the extracted text into a CSV file\n",
    "        with open(output_csv, 'w', encoding='utf-8') as f:\n",
    "            for line in extracted_text:\n",
    "                # Write each line of text as a new row in the CSV\n",
    "                f.write(f'\"{line.strip()}\"\\n')\n",
    "\n",
    "        print(f\"CSV {output_csv} created successfully from {pdf_path}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error while converting {pdf_path} to CSV: {e}\")\n",
    "\n",
    "    return output_csv\n",
    "\n",
    "# Function to import CSV files into Excel\n",
    "def import_csvs_to_excel(csv_files, excel_path):\n",
    "    \"\"\"\n",
    "    Imports CSV files into an Excel workbook, each CSV in a separate sheet.\n",
    "    \n",
    "    Parameters:\n",
    "    - csv_files: List of paths to the CSV files\n",
    "    - excel_path: Path to the Excel file\n",
    "    \"\"\"\n",
    "    # Create an Excel writer object\n",
    "    with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "        # Loop through each CSV file\n",
    "        for csv_file in csv_files:\n",
    "            try:\n",
    "                # Read the CSV file as a pandas DataFrame\n",
    "                df = pd.read_csv(csv_file, header=None, names=[\"Text\"])\n",
    "\n",
    "                # Check if the DataFrame is empty\n",
    "                if df.empty:\n",
    "                    print(f\"Warning: {csv_file} is empty or cannot be parsed.\")\n",
    "                else:\n",
    "                    # Generate a sheet name based on the file name (without extension)\n",
    "                    sheet_name = os.path.basename(csv_file).replace('.csv', '')\n",
    "\n",
    "                    # Write the DataFrame to a new sheet in the Excel workbook\n",
    "                    df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "                    print(f\"Data from {csv_file} has been imported into Excel sheet '{sheet_name}'.\")\n",
    "            except pd.errors.EmptyDataError:\n",
    "                print(f\"Error: {csv_file} is empty or has no data to parse.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error while importing {csv_file} to Excel: {e}\")\n",
    "\n",
    "    print(f\"All CSV files have been imported into {excel_path}\")\n",
    "\n",
    "# Main function to automate PDF to Excel conversion\n",
    "def automate_pdf_to_excel(pdf_files, output_directory, excel_file):\n",
    "    \"\"\"\n",
    "    Automates the process of converting PDFs to CSV (with all text) and importing them into Excel.\n",
    "    \n",
    "    Parameters:\n",
    "    - pdf_files: List of paths to the PDF files\n",
    "    - output_directory: Directory to save the converted CSVs\n",
    "    - excel_file: Path to the final Excel file\n",
    "    \"\"\"\n",
    "    # List to store paths of converted CSV files\n",
    "    csv_files = []\n",
    "\n",
    "    # Convert each PDF to CSV (extracting all text) and store the CSV paths\n",
    "    for pdf_file in pdf_files:\n",
    "        csv_file = convert_pdf_to_text_csv(pdf_file, output_directory)\n",
    "        csv_files.append(csv_file)\n",
    "\n",
    "    # Import all CSV files into the Excel file\n",
    "    import_csvs_to_excel(csv_files, excel_file)\n",
    "\n",
    "# Paths to the PDF files (replace with your actual file paths)\n",
    "pdf_files = [\n",
    "    \"/kaggle/input/pdfsss/pdf1.pdf\",\n",
    "    \"/kaggle/input/pdfsss/pdf2.pdf\",\n",
    "    \"/kaggle/input/pdfsss/pdf3.pdf\"\n",
    "]\n",
    "\n",
    "# Directory where the converted CSVs will be saved\n",
    "output_directory = \"/kaggle/working/\"\n",
    "\n",
    "# Path to the final Excel file where the data will be stored\n",
    "excel_file = \"/kaggle/working/imported_data.xlsx\"\n",
    "\n",
    "# Run the automation process to extract text from PDFs and import to Excel\n",
    "automate_pdf_to_excel(pdf_files, output_directory, excel_file)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5790577,
     "sourceId": 9512642,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22.497347,
   "end_time": "2024-09-30T18:32:01.393323",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-30T18:31:38.895976",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
