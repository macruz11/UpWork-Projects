{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a609d2c2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-02T23:34:42.188396Z",
     "iopub.status.busy": "2024-10-02T23:34:42.187850Z",
     "iopub.status.idle": "2024-10-02T23:34:43.400915Z",
     "shell.execute_reply": "2024-10-02T23:34:43.399174Z"
    },
    "papermill": {
     "duration": 1.223069,
     "end_time": "2024-10-02T23:34:43.404542",
     "exception": false,
     "start_time": "2024-10-02T23:34:42.181473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/pdfsss3/pdf2.pdf\n",
      "/kaggle/input/pdfsss3/pdf5.pdf\n",
      "/kaggle/input/pdfsss3/pdf4.pdf\n",
      "/kaggle/input/pdfsss3/pdf8.pdf\n",
      "/kaggle/input/pdfsss3/pdf1.pdf\n",
      "/kaggle/input/pdfsss3/pdf11.pdf\n",
      "/kaggle/input/pdfsss3/pdf7.pdf\n",
      "/kaggle/input/pdfsss3/pdf10.pdf\n",
      "/kaggle/input/pdfsss3/pdf9.pdf\n",
      "/kaggle/input/pdfsss3/pdf3.pdf\n",
      "/kaggle/input/pdfsss3/pdf6.pdf\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40fdad60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T23:34:43.414796Z",
     "iopub.status.busy": "2024-10-02T23:34:43.413771Z",
     "iopub.status.idle": "2024-10-02T23:35:02.213976Z",
     "shell.execute_reply": "2024-10-02T23:35:02.211799Z"
    },
    "papermill": {
     "duration": 18.809689,
     "end_time": "2024-10-02T23:35:02.218033",
     "exception": false,
     "start_time": "2024-10-02T23:34:43.408344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\r\n",
      "  Downloading pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\r\n",
      "Requirement already satisfied: openpyxl in /opt/conda/lib/python3.10/site-packages (3.1.5)\r\n",
      "Collecting pdfminer.six==20231228 (from pdfplumber)\r\n",
      "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\r\n",
      "Requirement already satisfied: Pillow>=9.1 in /opt/conda/lib/python3.10/site-packages (from pdfplumber) (10.3.0)\r\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\r\n",
      "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\r\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (42.0.8)\r\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\r\n",
      "Requirement already satisfied: et-xmlfile in /opt/conda/lib/python3.10/site-packages (from openpyxl) (1.1.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\r\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.16.0)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\r\n",
      "Downloading pdfplumber-0.11.4-py3-none-any.whl (59 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\r\n",
      "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.4 pypdfium2-4.30.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pdfplumber pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5831a96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T23:35:02.231102Z",
     "iopub.status.busy": "2024-10-02T23:35:02.230519Z",
     "iopub.status.idle": "2024-10-02T23:35:04.505228Z",
     "shell.execute_reply": "2024-10-02T23:35:04.503821Z"
    },
    "papermill": {
     "duration": 2.285763,
     "end_time": "2024-10-02T23:35:04.509019",
     "exception": false,
     "start_time": "2024-10-02T23:35:02.223256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No transformation matched for /kaggle/input/pdfsss3/pdf1.pdf\n",
      "Warning: No transformation matched for /kaggle/input/pdfsss3/pdf2.pdf\n",
      "Warning: No transformation matched for /kaggle/input/pdfsss3/pdf3.pdf\n",
      "Warning: No transformation matched for /kaggle/input/pdfsss3/pdf4.pdf\n",
      "Warning: No transformation matched for /kaggle/input/pdfsss3/pdf5.pdf\n",
      "All PDF files have been processed and saved to /kaggle/working/imported_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import os\n",
    "from openpyxl import Workbook\n",
    "\n",
    "# Function to extract text from a PDF, split into words, and store each row as a dictionary\n",
    "def pdf_to_dicts(pdf_file):\n",
    "    rows_list = []  # List to hold all rows as dictionaries\n",
    "    with pdfplumber.open(pdf_file) as pdf:\n",
    "        # Iterate through pages\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                # Split text by newlines to get individual lines\n",
    "                lines = text.split('\\n')\n",
    "                for line in lines:\n",
    "                    # Split each line into words based on spaces\n",
    "                    words = line.split()\n",
    "                    # Create a dictionary where keys are word indices and values are the words\n",
    "                    word_dict = {i: word for i, word in enumerate(words)}\n",
    "                    # Append the dictionary to the list of rows\n",
    "                    rows_list.append(word_dict)\n",
    "    return rows_list  # Returns a list of dictionaries, each representing a row\n",
    "\n",
    "# Function to convert the list of dictionaries into a DataFrame\n",
    "def dicts_to_dataframe(rows_list):\n",
    "    # Convert the list of dictionaries into a DataFrame\n",
    "    return pd.DataFrame(rows_list).fillna('')  # Fill NaNs with empty strings to avoid issues\n",
    "\n",
    "# Function to transform the DataFrame based on specific conditions\n",
    "def transform_dataframe(df):\n",
    "    pd_rows, pd_cols = df.shape\n",
    "\n",
    "    def validate_df(row_num, col_num):\n",
    "        if pd_rows > row_num and pd_cols > col_num:\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Error: DataFrame does not have enough rows ({pd_rows}) or columns ({pd_cols}) for the condition at row {row_num} and column {col_num}.\")\n",
    "            return False\n",
    "\n",
    "    # CANOPY transformation\n",
    "    if validate_df(0, 0) and df.iloc[0, 0] == \"CANOPY\":\n",
    "        blank_row = pd.Series([''] * pd_cols, index=df.columns)\n",
    "        df = pd.concat([df, blank_row.to_frame().T], ignore_index=True)\n",
    "\n",
    "        column_names = [\n",
    "            'INSURANCE_PROVIDER', 'CHEQUE_#', 'CHEQUE_DATE', 'BATCH_ID', 'DATE_FILLED', \n",
    "            'CLAIM_#', 'MEMBER_ID', 'NAME', 'BENEFIT', 'REF._NO', 'STAT', 'CHARGED', \n",
    "            'COPAY', 'EXCLUDED', 'DEDUCTIBLE', '%', 'PAYABLE', 'FEE', 'GCT', 'TOTAL', \n",
    "            'REJECT_REASON', 'REMARK_CODE'\n",
    "        ]\n",
    "        column_names_row = pd.Series(column_names + [''] * (pd_cols - len(column_names)), index=df.columns)\n",
    "        df = pd.concat([df, column_names_row.to_frame().T], ignore_index=True)\n",
    "\n",
    "        if pd_rows > 10:\n",
    "            data_to_copy = df.iloc[5:pd_rows-5, 0:13]\n",
    "            df = pd.concat([df, data_to_copy], ignore_index=True)\n",
    "\n",
    "        return df, 'CANOPY'\n",
    "\n",
    "    # GUARDIAN transformation\n",
    "    if validate_df(7, 0) and df.iloc[7, 0] == \"GUARDIAN\":\n",
    "        blank_row = pd.Series([''] * pd_cols, index=df.columns)\n",
    "        df = pd.concat([df, blank_row.to_frame().T], ignore_index=True)\n",
    "\n",
    "        column_names = [\n",
    "            'INSURANCE_PROVIDER', 'CHEQUE_#', 'CHEQUE_DATE', 'BATCH_ID', 'DATE_FILLED', \n",
    "            'CLAIM_#', 'MEMBER_ID', 'NAME', 'BENEFIT', 'REF._NO', 'STAT', 'CHARGED', \n",
    "            'COPAY', 'EXCLUDED', 'DEDUCTIBLE', '%', 'PAYABLE', 'FEE', 'GCT', 'TOTAL', \n",
    "            'REJECT_REASON', 'REMARK_CODE'\n",
    "        ]\n",
    "        column_names_row = pd.Series(column_names + [''] * (pd_cols - len(column_names)), index=df.columns)\n",
    "        df = pd.concat([df, column_names_row.to_frame().T], ignore_index=True)\n",
    "\n",
    "        if pd_rows > 17:\n",
    "            data_to_copy = df.iloc[10:pd_rows-7, 0:14]\n",
    "            df = pd.concat([df, data_to_copy], ignore_index=True)\n",
    "\n",
    "        return df, 'GUARDIAN'\n",
    "\n",
    "    # SAGICOR transformation\n",
    "    if validate_df(1, 0) and df.iloc[0, 0] == \"Sagicor\":\n",
    "        blank_row = pd.Series([''] * pd_cols, index=df.columns)\n",
    "        df = pd.concat([df, blank_row.to_frame().T], ignore_index=True)\n",
    "\n",
    "        column_names = [\n",
    "            'INSURANCE_PROVIDER', 'CHEQUE_#', 'CHEQUE_DATE', 'BATCH_ID', 'DATE_FILLED', \n",
    "            'CLAIM_#', 'MEMBER_ID', 'NAME', 'BENEFIT', 'REF._NO', 'STAT', 'CHARGED', \n",
    "            'COPAY', 'EXCLUDED', 'DEDUCTIBLE', '%', 'PAYABLE', 'FEE', 'GCT', 'TOTAL', \n",
    "            'REJECT_REASON', 'REMARK_CODE'\n",
    "        ]\n",
    "        column_names_row = pd.Series(column_names + [''] * (pd_cols - len(column_names)), index=df.columns)\n",
    "        df = pd.concat([df, column_names_row.to_frame().T], ignore_index=True)\n",
    "\n",
    "        rows_to_delete = [\"PAGE\", \"PROPHYSIO\", \"134CONSTANTSPRINGROAD\", \"KINGSTON10\", \n",
    "                          \"PROVIDERTAXID:\", \"28-48BarbadosAvenue.,Kingston5,JamaicaW.I.\", \n",
    "                          \"Telephone:(876)929-8920-9\", \"YOU\", \"-\"]\n",
    "        df = df[~df.iloc[:, 0].str.startswith(tuple(rows_to_delete), na=False)]\n",
    "        df = df.dropna(how='all').reset_index(drop=True)\n",
    "\n",
    "        return df, 'SAGICOR'\n",
    "\n",
    "    return df, None  # No valid transformation\n",
    "\n",
    "# Process PDFs to Excel with transformations, saving each transformation to a separate sheet\n",
    "def process_pdfs_to_excel(pdf_files, output_directory, excel_file):\n",
    "    wb = Workbook()\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        # Convert PDF text into dictionaries\n",
    "        rows_list = pdf_to_dicts(pdf_file)\n",
    "\n",
    "        # Convert the dictionaries into a DataFrame\n",
    "        df = dicts_to_dataframe(rows_list)\n",
    "\n",
    "        # Apply transformations based on conditions\n",
    "        transformed_df, sheet_name = transform_dataframe(df)\n",
    "\n",
    "        if sheet_name:\n",
    "            # Add the transformed DataFrame to a separate sheet in the Excel file\n",
    "            ws = wb.create_sheet(sheet_name)\n",
    "            for r in transformed_df.itertuples(index=False):\n",
    "                ws.append(r)\n",
    "            print(f\"Data from {pdf_file} has been transformed and saved to sheet '{sheet_name}'\")\n",
    "        else:\n",
    "            print(f\"Warning: No transformation matched for {pdf_file}\")\n",
    "\n",
    "    # Save the workbook with all the sheets\n",
    "    wb.save(excel_file)\n",
    "    print(f\"All PDF files have been processed and saved to {excel_file}\")\n",
    "\n",
    "# Paths to the PDF files (replace with your actual file paths)\n",
    "pdf_files = [\n",
    "    \"/kaggle/input/pdfsss3/pdf1.pdf\",\n",
    "    \"/kaggle/input/pdfsss3/pdf2.pdf\",\n",
    "    \"/kaggle/input/pdfsss3/pdf3.pdf\",\n",
    "    \"/kaggle/input/pdfsss3/pdf4.pdf\",\n",
    "    \"/kaggle/input/pdfsss3/pdf5.pdf\",\n",
    "]\n",
    "\n",
    "# Directory where the converted CSVs will be saved\n",
    "output_directory = \"/kaggle/working/\"\n",
    "\n",
    "# Path to the final Excel file where the data will be stored\n",
    "excel_file = \"/kaggle/working/imported_data.xlsx\"\n",
    "\n",
    "# Run the process to convert PDFs to Excel and apply transformations\n",
    "process_pdfs_to_excel(pdf_files, output_directory, excel_file)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5801120,
     "sourceId": 9526538,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 26.923278,
   "end_time": "2024-10-02T23:35:05.442460",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-02T23:34:38.519182",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
