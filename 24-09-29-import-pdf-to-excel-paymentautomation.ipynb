{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78fc3f39",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-02T23:24:21.626009Z",
     "iopub.status.busy": "2024-10-02T23:24:21.625580Z",
     "iopub.status.idle": "2024-10-02T23:24:22.629297Z",
     "shell.execute_reply": "2024-10-02T23:24:22.627908Z"
    },
    "papermill": {
     "duration": 1.011163,
     "end_time": "2024-10-02T23:24:22.632052",
     "exception": false,
     "start_time": "2024-10-02T23:24:21.620889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/pdfsss3/pdf2.pdf\n",
      "/kaggle/input/pdfsss3/pdf5.pdf\n",
      "/kaggle/input/pdfsss3/pdf4.pdf\n",
      "/kaggle/input/pdfsss3/pdf8.pdf\n",
      "/kaggle/input/pdfsss3/pdf1.pdf\n",
      "/kaggle/input/pdfsss3/pdf11.pdf\n",
      "/kaggle/input/pdfsss3/pdf7.pdf\n",
      "/kaggle/input/pdfsss3/pdf10.pdf\n",
      "/kaggle/input/pdfsss3/pdf9.pdf\n",
      "/kaggle/input/pdfsss3/pdf3.pdf\n",
      "/kaggle/input/pdfsss3/pdf6.pdf\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd014f50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T23:24:22.639437Z",
     "iopub.status.busy": "2024-10-02T23:24:22.638906Z",
     "iopub.status.idle": "2024-10-02T23:24:36.798939Z",
     "shell.execute_reply": "2024-10-02T23:24:36.797205Z"
    },
    "papermill": {
     "duration": 14.166258,
     "end_time": "2024-10-02T23:24:36.801369",
     "exception": false,
     "start_time": "2024-10-02T23:24:22.635111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\r\n",
      "  Downloading pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\r\n",
      "Requirement already satisfied: openpyxl in /opt/conda/lib/python3.10/site-packages (3.1.5)\r\n",
      "Collecting pdfminer.six==20231228 (from pdfplumber)\r\n",
      "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\r\n",
      "Requirement already satisfied: Pillow>=9.1 in /opt/conda/lib/python3.10/site-packages (from pdfplumber) (10.3.0)\r\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\r\n",
      "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\r\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (42.0.8)\r\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\r\n",
      "Requirement already satisfied: et-xmlfile in /opt/conda/lib/python3.10/site-packages (from openpyxl) (1.1.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\r\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.16.0)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\r\n",
      "Downloading pdfplumber-0.11.4-py3-none-any.whl (59 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\r\n",
      "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.4 pypdfium2-4.30.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pdfplumber pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22efe30b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T23:24:36.810660Z",
     "iopub.status.busy": "2024-10-02T23:24:36.810210Z",
     "iopub.status.idle": "2024-10-02T23:24:38.364924Z",
     "shell.execute_reply": "2024-10-02T23:24:38.363657Z"
    },
    "papermill": {
     "duration": 1.562438,
     "end_time": "2024-10-02T23:24:38.367318",
     "exception": false,
     "start_time": "2024-10-02T23:24:36.804880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: DataFrame does not have enough rows (3) or columns (3) for the condition at row 7 and column 0.\n",
      "Warning: No transformation matched for /kaggle/input/pdfsss3/pdf1.pdf\n",
      "Error: DataFrame does not have enough rows (3) or columns (3) for the condition at row 7 and column 0.\n",
      "Warning: No transformation matched for /kaggle/input/pdfsss3/pdf2.pdf\n",
      "Error: DataFrame does not have enough rows (7) or columns (2) for the condition at row 7 and column 0.\n",
      "Warning: No transformation matched for /kaggle/input/pdfsss3/pdf3.pdf\n",
      "Error: DataFrame does not have enough rows (7) or columns (2) for the condition at row 7 and column 0.\n",
      "Warning: No transformation matched for /kaggle/input/pdfsss3/pdf4.pdf\n",
      "Error: DataFrame does not have enough rows (7) or columns (2) for the condition at row 7 and column 0.\n",
      "Warning: No transformation matched for /kaggle/input/pdfsss3/pdf5.pdf\n",
      "All PDF files have been processed and saved to /kaggle/working/imported_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "from openpyxl import Workbook\n",
    "\n",
    "# Function to extract all text from a PDF, split it into words, and save it to CSV\n",
    "def pdf_to_csv(pdf_file, csv_file):\n",
    "    with pdfplumber.open(pdf_file) as pdf:\n",
    "        word_rows = []  # List to hold rows of words\n",
    "\n",
    "        # Extract text from each page of the PDF\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text()\n",
    "\n",
    "            # Split the text into lines\n",
    "            if text:\n",
    "                lines = text.split('\\n')\n",
    "\n",
    "                # For each line, split it into words based on spaces and add to word_rows\n",
    "                for line in lines:\n",
    "                    words = line.split()  # Split the line by spaces into words\n",
    "                    word_rows.append(words)  # Append the list of words as a row\n",
    "\n",
    "        # Save the extracted words to a CSV file (each word in a separate cell)\n",
    "        with open(csv_file, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(word_rows)  # Each row is written as a list of words\n",
    "\n",
    "# Function to transform the DataFrame based on specific conditions\n",
    "def transform_dataframe(df):\n",
    "    pd_rows, pd_cols = df.shape\n",
    "\n",
    "    def validate_df(row_num, col_num):\n",
    "        if pd_rows > row_num and pd_cols > col_num:\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Error: DataFrame does not have enough rows ({pd_rows}) or columns ({pd_cols}) for the condition at row {row_num} and column {col_num}.\")\n",
    "            return False\n",
    "\n",
    "    # CANOPY transformation\n",
    "    if validate_df(1, 0) and df.iloc[0, 0] == \"CANOPY\":\n",
    "        blank_row = pd.Series([''] * pd_cols, index=df.columns)\n",
    "        df = pd.concat([df, blank_row.to_frame().T], ignore_index=True)\n",
    "\n",
    "        column_names = [\n",
    "            'INSURANCE_PROVIDER', 'CHEQUE_#', 'CHEQUE_DATE', 'BATCH_ID', 'DATE_FILLED', \n",
    "            'CLAIM_#', 'MEMBER_ID', 'NAME', 'BENEFIT', 'REF._NO', 'STAT', 'CHARGED', \n",
    "            'COPAY', 'EXCLUDED', 'DEDUCTIBLE', '%', 'PAYABLE', 'FEE', 'GCT', 'TOTAL', \n",
    "            'REJECT_REASON', 'REMARK_CODE'\n",
    "        ]\n",
    "        column_names_row = pd.Series(column_names + [''] * (pd_cols - len(column_names)), index=df.columns)\n",
    "        df = pd.concat([df, column_names_row.to_frame().T], ignore_index=True)\n",
    "\n",
    "        if pd_rows > 10:\n",
    "            data_to_copy = df.iloc[5:pd_rows-5, 0:13]\n",
    "            df = pd.concat([df, data_to_copy], ignore_index=True)\n",
    "\n",
    "        return df, 'CANOPY'\n",
    "\n",
    "    # GUARDIAN transformation\n",
    "    if validate_df(7, 0) and df.iloc[7, 0] == \"GUARDIAN\":\n",
    "        blank_row = pd.Series([''] * pd_cols, index=df.columns)\n",
    "        df = pd.concat([df, blank_row.to_frame().T], ignore_index=True)\n",
    "\n",
    "        column_names = [\n",
    "            'INSURANCE_PROVIDER', 'CHEQUE_#', 'CHEQUE_DATE', 'BATCH_ID', 'DATE_FILLED', \n",
    "            'CLAIM_#', 'MEMBER_ID', 'NAME', 'BENEFIT', 'REF._NO', 'STAT', 'CHARGED', \n",
    "            'COPAY', 'EXCLUDED', 'DEDUCTIBLE', '%', 'PAYABLE', 'FEE', 'GCT', 'TOTAL', \n",
    "            'REJECT_REASON', 'REMARK_CODE'\n",
    "        ]\n",
    "        column_names_row = pd.Series(column_names + [''] * (pd_cols - len(column_names)), index=df.columns)\n",
    "        df = pd.concat([df, column_names_row.to_frame().T], ignore_index=True)\n",
    "\n",
    "        if pd_rows > 17:\n",
    "            data_to_copy = df.iloc[10:pd_rows-7, 0:14]\n",
    "            df = pd.concat([df, data_to_copy], ignore_index=True)\n",
    "\n",
    "        return df, 'GUARDIAN'\n",
    "\n",
    "    # SAGICOR transformation\n",
    "    if validate_df(1, 0) and df.iloc[0, 0] == \"Sagicor\":\n",
    "        blank_row = pd.Series([''] * pd_cols, index=df.columns)\n",
    "        df = pd.concat([df, blank_row.to_frame().T], ignore_index=True)\n",
    "\n",
    "        column_names = [\n",
    "            'INSURANCE_PROVIDER', 'CHEQUE_#', 'CHEQUE_DATE', 'BATCH_ID', 'DATE_FILLED', \n",
    "            'CLAIM_#', 'MEMBER_ID', 'NAME', 'BENEFIT', 'REF._NO', 'STAT', 'CHARGED', \n",
    "            'COPAY', 'EXCLUDED', 'DEDUCTIBLE', '%', 'PAYABLE', 'FEE', 'GCT', 'TOTAL', \n",
    "            'REJECT_REASON', 'REMARK_CODE'\n",
    "        ]\n",
    "        column_names_row = pd.Series(column_names + [''] * (pd_cols - len(column_names)), index=df.columns)\n",
    "        df = pd.concat([df, column_names_row.to_frame().T], ignore_index=True)\n",
    "\n",
    "        rows_to_delete = [\"PAGE\", \"PROPHYSIO\", \"134CONSTANTSPRINGROAD\", \"KINGSTON10\", \n",
    "                          \"PROVIDERTAXID:\", \"28-48BarbadosAvenue.,Kingston5,JamaicaW.I.\", \n",
    "                          \"Telephone:(876)929-8920-9\", \"YOU\", \"-\"]\n",
    "        df = df[~df.iloc[:, 0].str.startswith(tuple(rows_to_delete), na=False)]\n",
    "        df = df.dropna(how='all').reset_index(drop=True)\n",
    "\n",
    "        return df, 'SAGICOR'\n",
    "\n",
    "    return df, None  # No valid transformation\n",
    "\n",
    "# Process PDFs to Excel with transformations, saving each transformation to a separate sheet\n",
    "def process_pdfs_to_excel(pdf_files, output_directory, excel_file):\n",
    "    wb = Workbook()\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        # Convert PDF to CSV\n",
    "        csv_file = os.path.join(output_directory, os.path.basename(pdf_file).replace('.pdf', '.csv'))\n",
    "        pdf_to_csv(pdf_file, csv_file)\n",
    "\n",
    "        try:\n",
    "            # Read the generated CSV into a DataFrame, with handling for variable columns\n",
    "            df = pd.read_csv(csv_file, header=None, on_bad_lines='skip')\n",
    "\n",
    "            # Apply transformations based on conditions\n",
    "            transformed_df, sheet_name = transform_dataframe(df)\n",
    "\n",
    "            if sheet_name:\n",
    "                # Add the transformed DataFrame to a separate sheet in the Excel file\n",
    "                ws = wb.create_sheet(sheet_name)\n",
    "                for r in transformed_df.itertuples(index=False):\n",
    "                    ws.append(r)\n",
    "                print(f\"Data from {pdf_file} has been transformed and saved to sheet '{sheet_name}'\")\n",
    "            else:\n",
    "                print(f\"Warning: No transformation matched for {pdf_file}\")\n",
    "\n",
    "        except pd.errors.ParserError as e:\n",
    "            print(f\"Error reading {csv_file}: {e}\")\n",
    "\n",
    "    # Save the workbook with all the sheets\n",
    "    wb.save(excel_file)\n",
    "    print(f\"All PDF files have been processed and saved to {excel_file}\")\n",
    "\n",
    "# Paths to the PDF files (replace with your actual file paths)\n",
    "pdf_files = [\n",
    "    \"/kaggle/input/pdfsss3/pdf1.pdf\",\n",
    "    \"/kaggle/input/pdfsss3/pdf2.pdf\",\n",
    "    \"/kaggle/input/pdfsss3/pdf3.pdf\",\n",
    "    \"/kaggle/input/pdfsss3/pdf4.pdf\",\n",
    "    \"/kaggle/input/pdfsss3/pdf5.pdf\",\n",
    "]\n",
    "\n",
    "# Directory where the converted CSVs will be saved\n",
    "output_directory = \"/kaggle/working/\"\n",
    "\n",
    "# Path to the final Excel file where the data will be stored\n",
    "excel_file = \"/kaggle/working/imported_data.xlsx\"\n",
    "\n",
    "# Run the process to convert PDFs to Excel and apply transformations\n",
    "process_pdfs_to_excel(pdf_files, output_directory, excel_file)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5801120,
     "sourceId": 9526538,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20.317303,
   "end_time": "2024-10-02T23:24:38.992360",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-02T23:24:18.675057",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
